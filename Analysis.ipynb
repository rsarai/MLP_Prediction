{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UBE_DADOS_DEFASADOS.xls\n",
    "Contains values with diferent lags sizes for each of the attributes: [\"ATP\",\"RBG\",\"BLS\",\"SFB\",\"FZB\",\"UBE\"]\n",
    "\n",
    "## Dados UBE.csv\n",
    "Contains only the main values. Should use this to build a new input set with the desired lags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>ATP</th>\n",
       "      <th>RBG</th>\n",
       "      <th>BLS</th>\n",
       "      <th>SFB</th>\n",
       "      <th>FZB</th>\n",
       "      <th>UBE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>02/03/1973</td>\n",
       "      <td>250</td>\n",
       "      <td>244</td>\n",
       "      <td>91</td>\n",
       "      <td>214</td>\n",
       "      <td>37</td>\n",
       "      <td>575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>03/03/1973</td>\n",
       "      <td>191</td>\n",
       "      <td>305</td>\n",
       "      <td>97</td>\n",
       "      <td>208</td>\n",
       "      <td>36</td>\n",
       "      <td>643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>04/03/1973</td>\n",
       "      <td>169</td>\n",
       "      <td>380</td>\n",
       "      <td>115</td>\n",
       "      <td>207</td>\n",
       "      <td>36</td>\n",
       "      <td>727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>05/03/1973</td>\n",
       "      <td>136</td>\n",
       "      <td>290</td>\n",
       "      <td>114</td>\n",
       "      <td>201</td>\n",
       "      <td>38</td>\n",
       "      <td>615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>06/03/1973</td>\n",
       "      <td>131</td>\n",
       "      <td>286</td>\n",
       "      <td>100</td>\n",
       "      <td>196</td>\n",
       "      <td>38</td>\n",
       "      <td>605</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  ATP  RBG  BLS  SFB  FZB  UBE\n",
       "0  02/03/1973  250  244   91  214   37  575\n",
       "1  03/03/1973  191  305   97  208   36  643\n",
       "2  04/03/1973  169  380  115  207   36  727\n",
       "3  05/03/1973  136  290  114  201   38  615\n",
       "4  06/03/1973  131  286  100  196   38  605"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_path='Data/Dados UBE.csv'\n",
    "df = pd.read_csv(dataset_path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_lags = 8\n",
    "def create_lagged_dataset(df, number_of_lags=8):\n",
    "    colunms_shifted = []\n",
    "    for colunm in df:\n",
    "        if colunm == \"Date\":\n",
    "#             colunms_shifted += [df[colunm]]\n",
    "            continue\n",
    "\n",
    "        colunm_data = df[colunm]\n",
    "        colunms_shifted += [colunm_data.shift(i).rename(colunm_data.name + \"_\" + str(i)) for i in range(number_of_lags)] \n",
    "\n",
    "    lagged_colunms = pd.concat(colunms_shifted, axis=1, sort=False)\n",
    "    return lagged_colunms\n",
    "\n",
    "new_df = create_lagged_dataset(df, number_of_lags)\n",
    "new_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get results\n",
    "results_df = new_df[[\"ATP_0\", \"RBG_0\", \"BLS_0\", \"SFB_0\", \"FZB_0\", \"UBE_0\"]]\n",
    "\n",
    "# Drop results from new_df\n",
    "df_without_answers = new_df.drop([\"ATP_0\", \"RBG_0\", \"BLS_0\", \"SFB_0\", \"FZB_0\", \"UBE_0\"], axis=1)\n",
    "\n",
    "# Normalize\n",
    "from sklearn import preprocessing\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "cols = results_df.columns\n",
    "results_df_scaled = min_max_scaler.fit_transform(results_df)\n",
    "results_df_normalized = pd.DataFrame(results_df_scaled, columns=cols)\n",
    "\n",
    "\n",
    "cols = df_without_answers.columns\n",
    "df_without_answers_scaled = min_max_scaler.fit_transform(df_without_answers)\n",
    "df_without_answers_normalized = pd.DataFrame(df_without_answers_scaled, columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ATP_0', 'RBG_0', 'BLS_0', 'SFB_0', 'FZB_0', 'UBE_0'], dtype='object')"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df_normalized.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates train, test, and validation data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_x, test_x, train_y, test_y = train_test_split(\n",
    "    df_without_answers.values, \n",
    "    results_df.values,\n",
    "    test_size=0.25\n",
    ")\n",
    "\n",
    "# Reserve a part of the samples for validation\n",
    "percentage_n = percentage(20, len(train_x))\n",
    "percentage_n = int(percentage_n)\n",
    "val_x = train_x[-percentage_n:]\n",
    "val_y = train_y[-percentage_n:]\n",
    "train_x = train_x[:-percentage_n]\n",
    "train_y = train_y[:-percentage_n]\n",
    "\n",
    "train_set = (train_x, train_y)\n",
    "test_set = (test_x, test_y)\n",
    "validation_set = (val_x, val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Fit model on training data\n",
      "Train on 10241 samples, validate on 2560 samples\n",
      "Epoch 1/50\n",
      "10241/10241 [==============================] - 0s 24us/step - loss: 11815.2250 - mean_absolute_percentage_error: 19.2170 - MSE: 5268.7056 - val_loss: 5879.8057 - val_mean_absolute_percentage_error: 12.4045 - val_MSE: 2132.9082\n",
      "Epoch 2/50\n",
      "10241/10241 [==============================] - 0s 17us/step - loss: 5056.0735 - mean_absolute_percentage_error: 12.0337 - MSE: 1853.9551 - val_loss: 4382.5703 - val_mean_absolute_percentage_error: 13.0524 - val_MSE: 1921.4827\n",
      "Epoch 3/50\n",
      "10241/10241 [==============================] - 0s 17us/step - loss: 3961.8337 - mean_absolute_percentage_error: 11.5992 - MSE: 1705.5264 - val_loss: 3739.0243 - val_mean_absolute_percentage_error: 10.9273 - val_MSE: 1872.4658\n",
      "Epoch 4/50\n",
      "10241/10241 [==============================] - 0s 17us/step - loss: 3455.6497 - mean_absolute_percentage_error: 10.7879 - MSE: 1583.9504 - val_loss: 3295.9721 - val_mean_absolute_percentage_error: 9.6795 - val_MSE: 1585.6337\n",
      "Epoch 5/50\n",
      "10241/10241 [==============================] - 0s 17us/step - loss: 3258.0017 - mean_absolute_percentage_error: 10.2154 - MSE: 1534.3336 - val_loss: 3197.0929 - val_mean_absolute_percentage_error: 9.9055 - val_MSE: 1562.3004\n",
      "Epoch 6/50\n",
      "10241/10241 [==============================] - 0s 16us/step - loss: 3108.2177 - mean_absolute_percentage_error: 9.7237 - MSE: 1471.7411 - val_loss: 3064.1276 - val_mean_absolute_percentage_error: 9.2734 - val_MSE: 1517.6001\n",
      "Epoch 7/50\n",
      "10241/10241 [==============================] - 0s 17us/step - loss: 3020.5365 - mean_absolute_percentage_error: 9.7706 - MSE: 1448.4724 - val_loss: 2980.1580 - val_mean_absolute_percentage_error: 9.4684 - val_MSE: 1498.2405\n",
      "Epoch 8/50\n",
      "10241/10241 [==============================] - 0s 17us/step - loss: 2942.7946 - mean_absolute_percentage_error: 9.6528 - MSE: 1420.3154 - val_loss: 2924.2196 - val_mean_absolute_percentage_error: 9.2694 - val_MSE: 1450.7538\n",
      "Epoch 9/50\n",
      "10241/10241 [==============================] - 0s 17us/step - loss: 2880.1594 - mean_absolute_percentage_error: 9.4117 - MSE: 1397.8840 - val_loss: 2953.1150 - val_mean_absolute_percentage_error: 9.4991 - val_MSE: 1475.3210\n",
      "Epoch 10/50\n",
      "10241/10241 [==============================] - 0s 17us/step - loss: 2851.6962 - mean_absolute_percentage_error: 9.5247 - MSE: 1403.5730 - val_loss: 2882.3551 - val_mean_absolute_percentage_error: 10.1910 - val_MSE: 1518.8191\n",
      "Epoch 11/50\n",
      "10241/10241 [==============================] - 0s 17us/step - loss: 2788.9542 - mean_absolute_percentage_error: 9.3068 - MSE: 1371.3405 - val_loss: 2794.4268 - val_mean_absolute_percentage_error: 8.7927 - val_MSE: 1405.5237\n",
      "Epoch 12/50\n",
      "10241/10241 [==============================] - 0s 17us/step - loss: 2768.8100 - mean_absolute_percentage_error: 9.5279 - MSE: 1378.8523 - val_loss: 2754.3703 - val_mean_absolute_percentage_error: 8.7823 - val_MSE: 1392.7249\n",
      "Epoch 13/50\n",
      "10241/10241 [==============================] - 0s 18us/step - loss: 2741.1380 - mean_absolute_percentage_error: 9.4560 - MSE: 1373.0193 - val_loss: 2741.4814 - val_mean_absolute_percentage_error: 9.2555 - val_MSE: 1386.7888\n",
      "Epoch 14/50\n",
      "10241/10241 [==============================] - 0s 16us/step - loss: 2689.8776 - mean_absolute_percentage_error: 9.2281 - MSE: 1341.0125 - val_loss: 2698.3167 - val_mean_absolute_percentage_error: 8.7883 - val_MSE: 1368.5757\n",
      "Epoch 15/50\n",
      "10241/10241 [==============================] - 0s 17us/step - loss: 2689.7732 - mean_absolute_percentage_error: 9.4086 - MSE: 1358.2073 - val_loss: 3606.2559 - val_mean_absolute_percentage_error: 14.7756 - val_MSE: 2175.7729\n",
      "Epoch 16/50\n",
      "10241/10241 [==============================] - 0s 17us/step - loss: 2836.0206 - mean_absolute_percentage_error: 10.5635 - MSE: 1508.2869 - val_loss: 2729.1328 - val_mean_absolute_percentage_error: 8.9246 - val_MSE: 1471.0767\n",
      "Epoch 17/50\n",
      "10241/10241 [==============================] - 0s 19us/step - loss: 2641.3043 - mean_absolute_percentage_error: 8.9906 - MSE: 1334.6195 - val_loss: 2722.2186 - val_mean_absolute_percentage_error: 9.7628 - val_MSE: 1431.6866\n",
      "Epoch 18/50\n",
      "10241/10241 [==============================] - 0s 16us/step - loss: 2695.1161 - mean_absolute_percentage_error: 9.8250 - MSE: 1397.2916 - val_loss: 2646.9156 - val_mean_absolute_percentage_error: 8.7852 - val_MSE: 1408.3204\n",
      "Epoch 19/50\n",
      "10241/10241 [==============================] - 0s 17us/step - loss: 2615.8945 - mean_absolute_percentage_error: 9.0884 - MSE: 1331.2023 - val_loss: 2632.3810 - val_mean_absolute_percentage_error: 9.5237 - val_MSE: 1407.3123\n",
      "Epoch 20/50\n",
      "10241/10241 [==============================] - 0s 17us/step - loss: 2593.7481 - mean_absolute_percentage_error: 8.8600 - MSE: 1319.4194 - val_loss: 2618.8265 - val_mean_absolute_percentage_error: 8.5473 - val_MSE: 1398.1096\n",
      "Epoch 21/50\n",
      "10241/10241 [==============================] - 0s 16us/step - loss: 2581.9782 - mean_absolute_percentage_error: 9.0142 - MSE: 1318.2028 - val_loss: 2668.1234 - val_mean_absolute_percentage_error: 9.6493 - val_MSE: 1415.2776\n",
      "Epoch 22/50\n",
      "10241/10241 [==============================] - 0s 17us/step - loss: 2571.9698 - mean_absolute_percentage_error: 9.0930 - MSE: 1319.3488 - val_loss: 2573.9478 - val_mean_absolute_percentage_error: 8.0768 - val_MSE: 1336.8215\n",
      "Epoch 23/50\n",
      "10241/10241 [==============================] - 0s 17us/step - loss: 2562.1475 - mean_absolute_percentage_error: 8.9287 - MSE: 1317.9413 - val_loss: 2605.0161 - val_mean_absolute_percentage_error: 8.3168 - val_MSE: 1408.7892\n",
      "Epoch 24/50\n",
      "10241/10241 [==============================] - 0s 16us/step - loss: 2556.0895 - mean_absolute_percentage_error: 9.1469 - MSE: 1319.6403 - val_loss: 2569.9986 - val_mean_absolute_percentage_error: 8.7150 - val_MSE: 1348.0597\n",
      "Epoch 25/50\n",
      "10241/10241 [==============================] - 0s 16us/step - loss: 2537.9836 - mean_absolute_percentage_error: 9.2639 - MSE: 1310.3137 - val_loss: 2693.4776 - val_mean_absolute_percentage_error: 10.3982 - val_MSE: 1496.0219\n",
      "Epoch 26/50\n",
      "10241/10241 [==============================] - 0s 16us/step - loss: 2653.8016 - mean_absolute_percentage_error: 10.4856 - MSE: 1431.7019 - val_loss: 2555.2469 - val_mean_absolute_percentage_error: 8.4648 - val_MSE: 1366.3959\n",
      "Epoch 27/50\n",
      "10241/10241 [==============================] - 0s 17us/step - loss: 2520.6642 - mean_absolute_percentage_error: 9.0517 - MSE: 1307.1488 - val_loss: 2604.8183 - val_mean_absolute_percentage_error: 9.5747 - val_MSE: 1465.2285\n",
      "Epoch 28/50\n",
      "10241/10241 [==============================] - 0s 17us/step - loss: 2499.6704 - mean_absolute_percentage_error: 8.9571 - MSE: 1292.1886 - val_loss: 2540.2466 - val_mean_absolute_percentage_error: 8.4890 - val_MSE: 1343.3206\n",
      "Epoch 29/50\n",
      "10241/10241 [==============================] - 0s 17us/step - loss: 2507.6954 - mean_absolute_percentage_error: 9.1081 - MSE: 1307.0027 - val_loss: 2604.3807 - val_mean_absolute_percentage_error: 8.9686 - val_MSE: 1420.2512\n",
      "Epoch 30/50\n",
      "10241/10241 [==============================] - 0s 16us/step - loss: 2502.3908 - mean_absolute_percentage_error: 9.2194 - MSE: 1308.4365 - val_loss: 2503.5087 - val_mean_absolute_percentage_error: 8.5000 - val_MSE: 1352.3774\n",
      "Epoch 31/50\n",
      "10241/10241 [==============================] - 0s 16us/step - loss: 2470.1244 - mean_absolute_percentage_error: 8.8261 - MSE: 1283.9019 - val_loss: 2554.6209 - val_mean_absolute_percentage_error: 9.3575 - val_MSE: 1431.1277\n",
      "Epoch 32/50\n",
      "10241/10241 [==============================] - 0s 17us/step - loss: 2455.5795 - mean_absolute_percentage_error: 8.8325 - MSE: 1275.5560 - val_loss: 2511.0474 - val_mean_absolute_percentage_error: 8.5593 - val_MSE: 1372.7781\n",
      "Epoch 33/50\n",
      "10241/10241 [==============================] - 0s 17us/step - loss: 2446.7845 - mean_absolute_percentage_error: 8.7383 - MSE: 1272.5546 - val_loss: 2628.4206 - val_mean_absolute_percentage_error: 9.9200 - val_MSE: 1447.5813\n",
      "Epoch 34/50\n",
      "10241/10241 [==============================] - 0s 17us/step - loss: 2515.2702 - mean_absolute_percentage_error: 9.6470 - MSE: 1349.8292 - val_loss: 2477.4260 - val_mean_absolute_percentage_error: 8.0706 - val_MSE: 1343.4868\n",
      "Epoch 35/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10241/10241 [==============================] - 0s 17us/step - loss: 2436.0213 - mean_absolute_percentage_error: 8.8678 - MSE: 1274.8527 - val_loss: 2541.6100 - val_mean_absolute_percentage_error: 9.9701 - val_MSE: 1444.7045\n",
      "Epoch 36/50\n",
      "10241/10241 [==============================] - 0s 16us/step - loss: 2438.6917 - mean_absolute_percentage_error: 8.8937 - MSE: 1282.7407 - val_loss: 2474.1490 - val_mean_absolute_percentage_error: 8.3486 - val_MSE: 1362.0986\n",
      "Epoch 37/50\n",
      "10241/10241 [==============================] - 0s 17us/step - loss: 2423.3022 - mean_absolute_percentage_error: 8.6394 - MSE: 1269.9216 - val_loss: 2589.0663 - val_mean_absolute_percentage_error: 9.5897 - val_MSE: 1500.4177\n",
      "Epoch 38/50\n",
      "10241/10241 [==============================] - 0s 16us/step - loss: 2422.5570 - mean_absolute_percentage_error: 8.8576 - MSE: 1276.9546 - val_loss: 2501.0908 - val_mean_absolute_percentage_error: 8.6469 - val_MSE: 1412.1857\n",
      "Epoch 39/50\n",
      "10241/10241 [==============================] - 0s 17us/step - loss: 2413.8052 - mean_absolute_percentage_error: 8.7262 - MSE: 1271.8800 - val_loss: 2501.2971 - val_mean_absolute_percentage_error: 8.2352 - val_MSE: 1345.7218\n",
      "Epoch 40/50\n",
      "10241/10241 [==============================] - 0s 17us/step - loss: 2398.2783 - mean_absolute_percentage_error: 8.6840 - MSE: 1260.9607 - val_loss: 2452.8288 - val_mean_absolute_percentage_error: 8.3031 - val_MSE: 1336.8184\n",
      "Epoch 41/50\n",
      "10241/10241 [==============================] - 0s 17us/step - loss: 2401.5761 - mean_absolute_percentage_error: 8.8063 - MSE: 1268.4938 - val_loss: 2444.5387 - val_mean_absolute_percentage_error: 8.3523 - val_MSE: 1324.1118\n",
      "Epoch 42/50\n",
      "10241/10241 [==============================] - 0s 16us/step - loss: 2378.2625 - mean_absolute_percentage_error: 8.4612 - MSE: 1249.0070 - val_loss: 2461.0179 - val_mean_absolute_percentage_error: 8.1888 - val_MSE: 1347.1184\n",
      "Epoch 43/50\n",
      "10241/10241 [==============================] - 0s 16us/step - loss: 2405.5370 - mean_absolute_percentage_error: 8.8491 - MSE: 1282.7068 - val_loss: 2430.5152 - val_mean_absolute_percentage_error: 8.0684 - val_MSE: 1315.6088\n",
      "Epoch 44/50\n",
      "10241/10241 [==============================] - 0s 16us/step - loss: 2383.8548 - mean_absolute_percentage_error: 8.5795 - MSE: 1264.8710 - val_loss: 2486.2477 - val_mean_absolute_percentage_error: 8.3262 - val_MSE: 1376.5913\n",
      "Epoch 45/50\n",
      "10241/10241 [==============================] - 0s 17us/step - loss: 2379.4657 - mean_absolute_percentage_error: 8.6819 - MSE: 1267.4734 - val_loss: 2437.9740 - val_mean_absolute_percentage_error: 8.0423 - val_MSE: 1360.7432\n",
      "Epoch 46/50\n",
      "10241/10241 [==============================] - 0s 17us/step - loss: 2388.3845 - mean_absolute_percentage_error: 8.8350 - MSE: 1279.0828 - val_loss: 2414.0693 - val_mean_absolute_percentage_error: 9.0274 - val_MSE: 1350.8868\n",
      "Epoch 47/50\n",
      "10241/10241 [==============================] - 0s 16us/step - loss: 2342.9530 - mean_absolute_percentage_error: 8.5189 - MSE: 1236.2462 - val_loss: 2656.6737 - val_mean_absolute_percentage_error: 12.2124 - val_MSE: 1642.9451\n",
      "Epoch 48/50\n",
      "10241/10241 [==============================] - 0s 17us/step - loss: 2445.5836 - mean_absolute_percentage_error: 9.6847 - MSE: 1346.8546 - val_loss: 2500.6667 - val_mean_absolute_percentage_error: 9.9665 - val_MSE: 1472.9611\n",
      "Epoch 49/50\n",
      "10241/10241 [==============================] - 0s 17us/step - loss: 2356.6424 - mean_absolute_percentage_error: 8.7032 - MSE: 1257.4258 - val_loss: 2460.9709 - val_mean_absolute_percentage_error: 8.8968 - val_MSE: 1370.6279\n",
      "Epoch 50/50\n",
      "10241/10241 [==============================] - 0s 18us/step - loss: 2396.8387 - mean_absolute_percentage_error: 9.0923 - MSE: 1299.7181 - val_loss: 2401.3428 - val_mean_absolute_percentage_error: 7.9116 - val_MSE: 1334.3630\n",
      "\n",
      "# Evaluate on test data\n",
      "4267/4267 [==============================] - 0s 6us/step\n",
      "['loss', 'mean_absolute_percentage_error', 'MSE'], [2387.224423566076, 7.937178611755371, 1299.0172119140625]\n"
     ]
    }
   ],
   "source": [
    "model = create_network()\n",
    "print('# Fit model on training data')\n",
    "history = model.fit(train_set[0], train_set[1],\n",
    "                    batch_size=64,\n",
    "                    epochs=50,\n",
    "                    # We pass some validation for\n",
    "                    # monitoring validation loss and metrics\n",
    "                    # at the end of each epoch\n",
    "                    validation_data=validation_set)\n",
    "\n",
    "# Evaluate the model on the test data using `evaluate`\n",
    "print('\\n# Evaluate on test data')\n",
    "results = model.evaluate(test_set[0], test_set[1], batch_size=64)\n",
    "print(f\"{model.metrics_names}, {results}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['loss', 'mean_absolute_percentage_error', 'MSE']"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.metrics_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.regularizers import l2, l1\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "\n",
    "def create_network(input_size=6*(number_of_lags-1), hidden_layer_neurons=480, output_size=6, optimizer=\"adam\",\n",
    "                   activation_1_layer=\"relu\", activation_2_layer=\"linear\", regulazier_1_layer=l2(0.01),\n",
    "                   regulazier_2_layer=l2(0.01)):\n",
    "    classifier = Sequential()\n",
    "\n",
    "    #camada escondida\n",
    "    classifier.add(\n",
    "        Dense(\n",
    "            units=hidden_layer_neurons,\n",
    "            activation=activation_1_layer,\n",
    "            input_dim= input_size,\n",
    "            kernel_regularizer=regulazier_1_layer,\n",
    "            activity_regularizer=l1(0.01)\n",
    "        )\n",
    "    )\n",
    "\n",
    "    #camada de saida\n",
    "    classifier.add(\n",
    "        Dense(\n",
    "            units=output_size,\n",
    "            activation=activation_2_layer,\n",
    "            kernel_regularizer=regulazier_2_layer,\n",
    "            activity_regularizer=l1(0.01)\n",
    "        )\n",
    "    )\n",
    "\n",
    "    classifier.compile(optimizer=optimizer, loss='MSE', metrics=['mean_absolute_percentage_error','MSE'])\n",
    "\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-privacy",
   "language": "python",
   "name": "data-privacy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
